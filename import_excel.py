import pandas as pd
import os
from typing import Optional, Dict, Any, List
from werkzeug.utils import secure_filename
import uuid
from datetime import datetime
import numpy as np

# C·∫•u h√¨nh upload
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'xlsx', 'xls', 'csv'}
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB

def _safe_dict_records(df: pd.DataFrame) -> List[Dict[str, Any]]:
    """
    Safely convert DataFrame to dict records, handling non-JSON serializable types
    """
    try:
        # Replace all NaN/None values with empty string
        df_clean = df.copy()
        
        # Convert datetime columns to string
        for col in df_clean.columns:
            if pd.api.types.is_datetime64_any_dtype(df_clean[col]):
                df_clean[col] = df_clean[col].dt.strftime('%Y-%m-%d %H:%M:%S')
            elif pd.api.types.is_numeric_dtype(df_clean[col]):
                # Convert numeric NaN to 0 or empty string
                df_clean[col] = df_clean[col].fillna(0)
            else:
                # Convert all other types to string and handle NaN
                df_clean[col] = df_clean[col].astype(str).replace('nan', '')
        
        # Fill any remaining NaN values
        df_clean = df_clean.fillna('')
        
        return df_clean.to_dict('records')
    except Exception as e:
        print(f"Error in _safe_dict_records: {e}")
        # Fallback: convert everything to string
        try:
            df_str = df.fillna('').astype(str)
            return df_str.to_dict('records')
        except:
            return []

def ensure_upload_folder():
    """T·∫°o th∆∞ m·ª•c uploads n·∫øu ch∆∞a t·ªìn t·∫°i"""
    if not os.path.exists(UPLOAD_FOLDER):
        os.makedirs(UPLOAD_FOLDER)
        print(f"ƒê√£ t·∫°o th∆∞ m·ª•c: {UPLOAD_FOLDER}")

def allowed_file(filename: str) -> bool:
    """Ki·ªÉm tra file c√≥ ph·∫ßn m·ªü r·ªông h·ª£p l·ªá kh√¥ng"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def generate_unique_filename(filename: str) -> str:
    """T·∫°o t√™n file duy nh·∫•t ƒë·ªÉ tr√°nh tr√πng l·∫∑p"""
    secure_name = secure_filename(filename)
    name, ext = os.path.splitext(secure_name)
    unique_id = str(uuid.uuid4())[:8]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"{name}_{timestamp}_{unique_id}{ext}"

def save_uploaded_file(file_storage, custom_filename: Optional[str] = None) -> Dict[str, Any]:
    """
    L∆∞u file ƒë∆∞·ª£c upload v√† tr·∫£ v·ªÅ th√¥ng tin file
    
    Args:
        file_storage: File object t·ª´ Flask request
        custom_filename (str, optional): T√™n file t√πy ch·ªânh
    
    Returns:
        Dict[str, Any]: Th√¥ng tin v·ªÅ file ƒë√£ l∆∞u
    """
    try:
        ensure_upload_folder()
        
        if file_storage.filename == '':
            raise ValueError("Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c ch·ªçn")
        
        if not allowed_file(file_storage.filename):
            raise ValueError(f"Lo·∫°i file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Ch·ªâ ch·∫•p nh·∫≠n: {', '.join(ALLOWED_EXTENSIONS)}")
        
        # T·∫°o t√™n file an to√†n v√† duy nh·∫•t
        if custom_filename:
            filename = secure_filename(custom_filename)
            if not allowed_file(filename):
                filename = generate_unique_filename(file_storage.filename)
        else:
            filename = generate_unique_filename(file_storage.filename)
        
        file_path = os.path.join(UPLOAD_FOLDER, filename)
        
        # L∆∞u file
        file_storage.save(file_path)
        
        # L·∫•y th√¥ng tin file
        file_size = os.path.getsize(file_path)
        
        result = {
            'success': True,
            'filename': filename,
            'file_path': file_path,
            'file_size': file_size,
            'file_size_mb': round(file_size / (1024 * 1024), 2),
            'upload_time': datetime.now().isoformat(),
            'original_filename': file_storage.filename
        }
        
        print(f"ƒê√£ l∆∞u file th√†nh c√¥ng: {file_path} ({result['file_size_mb']} MB)")
        return result
        
    except Exception as e:
        print(f"L·ªói khi l∆∞u file: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

def process_uploaded_excel(file_info: Dict[str, Any]) -> Dict[str, Any]:
    """
    X·ª≠ l√Ω v√† ph√¢n t√≠ch file Excel ƒë√£ upload
    
    Args:
        file_info (Dict[str, Any]): Th√¥ng tin file t·ª´ save_uploaded_file()
    
    Returns:
        Dict[str, Any]: K·∫øt qu·∫£ ph√¢n t√≠ch file Excel
    """
    try:
        if not file_info.get('success'):
            raise ValueError(file_info.get('error', 'File upload kh√¥ng th√†nh c√¥ng'))
        
        file_path = file_info['file_path']
        
        # L·∫•y th√¥ng tin Excel
        excel_info = get_excel_info(file_path)
        
        # ƒê·ªçc sheet ƒë·∫ßu ti√™n
        df = read_excel_file(file_path)
        
        # T·∫°o summary
        result = {
            'success': True,
            'file_info': file_info,
            'excel_info': excel_info,
            'data_summary': {
                'total_rows': len(df),
                'total_columns': len(df.columns),
                'columns': list(df.columns),
                'dtypes': {col: str(dtype) for col, dtype in df.dtypes.items()},
                'null_counts': {col: int(count) for col, count in df.isnull().sum().items()},
                'sample_data': _safe_dict_records(df.head(5)) if not df.empty else []
            }
        }
        
        print(f"ƒê√£ ph√¢n t√≠ch file Excel th√†nh c√¥ng")
        print(f"D·ªØ li·ªáu: {result['data_summary']['total_rows']} d√≤ng, {result['data_summary']['total_columns']} c·ªôt")
        
        return result
        
    except Exception as e:
        print(f"L·ªói khi ph√¢n t√≠ch Excel: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'file_info': file_info
        }

def get_uploaded_files() -> List[Dict[str, Any]]:
    """L·∫•y danh s√°ch t·∫•t c·∫£ files ƒë√£ upload"""
    try:
        ensure_upload_folder()
        files = []
        
        for filename in os.listdir(UPLOAD_FOLDER):
            if allowed_file(filename):
                file_path = os.path.join(UPLOAD_FOLDER, filename)
                file_stat = os.stat(file_path)
                
                files.append({
                    'filename': filename,
                    'file_path': file_path,
                    'file_size_mb': round(file_stat.st_size / (1024 * 1024), 2),
                    'upload_time': datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                    'is_excel': filename.lower().endswith(('.xlsx', '.xls'))
                })
        
        # S·∫Øp x·∫øp theo th·ªùi gian upload (m·ªõi nh·∫•t tr∆∞·ªõc)
        files.sort(key=lambda x: x['upload_time'], reverse=True)
        return files
        
    except Exception as e:
        print(f"L·ªói khi l·∫•y danh s√°ch file: {str(e)}")
        return []

def delete_uploaded_file(filename: str) -> bool:
    """X√≥a file ƒë√£ upload"""
    try:
        file_path = os.path.join(UPLOAD_FOLDER, secure_filename(filename))
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"ƒê√£ x√≥a file: {filename}")
            return True
        else:
            print(f"File kh√¥ng t·ªìn t·∫°i: {filename}")
            return False
    except Exception as e:
        print(f"L·ªói khi x√≥a file: {str(e)}")
        return False

def read_excel_file(file_path: str, sheet_name: Optional[str] = None) -> pd.DataFrame:
    """
    ƒê·ªçc file Excel v√† tr·∫£ v·ªÅ DataFrame
    
    Args:
        file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel
        sheet_name (str, optional): T√™n sheet c·∫ßn ƒë·ªçc. N·∫øu None s·∫Ω ƒë·ªçc sheet ƒë·∫ßu ti√™n
    
    Returns:
        pd.DataFrame: D·ªØ li·ªáu t·ª´ file Excel
    
    Raises:
        FileNotFoundError: N·∫øu file kh√¥ng t·ªìn t·∫°i
        Exception: N·∫øu c√≥ l·ªói khi ƒë·ªçc file
    """
    try:
        # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File kh√¥ng t·ªìn t·∫°i: {file_path}")
        
        # ƒê·ªçc file Excel
        if sheet_name:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            print(f"ƒê√£ ƒë·ªçc th√†nh c√¥ng sheet '{sheet_name}' t·ª´ file: {file_path}")
        else:
            df = pd.read_excel(file_path)
            print(f"ƒê√£ ƒë·ªçc th√†nh c√¥ng file: {file_path}")
        
        return df
    
    except Exception as e:
        print(f"L·ªói khi ƒë·ªçc file Excel: {str(e)}")
        raise

def get_excel_info(file_path: str) -> Dict[str, Any]:
    """
    L·∫•y th√¥ng tin v·ªÅ file Excel (s·ªë sheet, t√™n c√°c sheet, etc.)
    
    Args:
        file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel
    
    Returns:
        Dict[str, Any]: Th√¥ng tin v·ªÅ file Excel
    """
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File kh√¥ng t·ªìn t·∫°i: {file_path}")
        
        # ƒê·ªçc t·∫•t c·∫£ sheet names
        excel_file = pd.ExcelFile(file_path)
        
        info = {
            'file_path': file_path,
            'sheet_names': excel_file.sheet_names,
            'number_of_sheets': len(excel_file.sheet_names),
            'file_size_mb': round(os.path.getsize(file_path) / (1024 * 1024), 2)
        }
        
        return info
    
    except Exception as e:
        print(f"L·ªói khi l·∫•y th√¥ng tin file Excel: {str(e)}")
        raise

def display_dataframe_info(df: pd.DataFrame, sample_rows: int = 5) -> None:
    """
    Hi·ªÉn th·ªã th√¥ng tin v·ªÅ DataFrame
    
    Args:
        df (pd.DataFrame): DataFrame c·∫ßn hi·ªÉn th·ªã th√¥ng tin
        sample_rows (int): S·ªë d√≤ng m·∫´u c·∫ßn hi·ªÉn th·ªã
    """
    print("=" * 50)
    print("TH√îNG TIN DATAFRAME:")
    print("=" * 50)
    print(f"K√≠ch th∆∞·ªõc: {df.shape[0]} d√≤ng, {df.shape[1]} c·ªôt")
    print(f"T√™n c√°c c·ªôt: {list(df.columns)}")
    print(f"Ki·ªÉu d·ªØ li·ªáu c√°c c·ªôt:")
    print(df.dtypes)
    print(f"\n{sample_rows} d√≤ng ƒë·∫ßu ti√™n:")
    print(df.head(sample_rows))
    
    # Ki·ªÉm tra d·ªØ li·ªáu null
    null_counts = df.isnull().sum()
    if null_counts.any():
        print(f"\nS·ªë l∆∞·ª£ng gi√° tr·ªã null trong m·ªói c·ªôt:")
        print(null_counts[null_counts > 0])
    else:
        print("\nKh√¥ng c√≥ gi√° tr·ªã null n√†o trong d·ªØ li·ªáu.")

def read_specific_columns(file_path: str, columns: list, sheet_name: Optional[str] = None) -> pd.DataFrame:
    """
    ƒê·ªçc ch·ªâ nh·ªØng c·ªôt c·ª• th·ªÉ t·ª´ file Excel
    
    Args:
        file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel
        columns (list): Danh s√°ch t√™n c·ªôt c·∫ßn ƒë·ªçc
        sheet_name (str, optional): T√™n sheet c·∫ßn ƒë·ªçc
    
    Returns:
        pd.DataFrame: DataFrame ch·ªâ ch·ª©a c√°c c·ªôt ƒë∆∞·ª£c ch·ªçn
    """
    try:
        df = read_excel_file(file_path, sheet_name)
        
        # Ki·ªÉm tra xem c√°c c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng
        missing_cols = [col for col in columns if col not in df.columns]
        if missing_cols:
            print(f"C·∫£nh b√°o: C√°c c·ªôt kh√¥ng t·ªìn t·∫°i: {missing_cols}")
            columns = [col for col in columns if col in df.columns]
        
        if not columns:
            raise ValueError("Kh√¥ng c√≥ c·ªôt n√†o h·ª£p l·ªá ƒë·ªÉ ƒë·ªçc")
        
        return df[columns]
    
    except Exception as e:
        print(f"L·ªói khi ƒë·ªçc c√°c c·ªôt c·ª• th·ªÉ: {str(e)}")
        raise

# Demo v√† test functions
if __name__ == "__main__":
    print("=" * 60)
    print("EXCEL UPLOAD & DOWNLOAD SYSTEM")
    print("=" * 60)
    
    # Ki·ªÉm tra files c√≥ s·∫µn trong uploads
    print("Ki·ªÉm tra files trong th∆∞ m·ª•c uploads...")
    uploaded_files = get_uploaded_files()
    
    if uploaded_files:
        print(f"T√¨m th·∫•y {len(uploaded_files)} file(s):")
        for i, file in enumerate(uploaded_files, 1):
            print(f"  {i}. {file['filename']} ({file['file_size_mb']} MB)")
        
        # Test v·ªõi file ƒë·∫ßu ti√™n
        test_file = uploaded_files[0]
        print(f"\nTesting v·ªõi file: {test_file['filename']}")
        
        try:
            # Test ƒë·ªçc info
            info = get_excel_info(test_file['file_path'])
            print(f"Th√¥ng tin Excel:")
            print(f"  - S·ªë sheets: {info['number_of_sheets']}")
            print(f"  - T√™n sheets: {info['sheet_names']}")
            print(f"  - K√≠ch th∆∞·ªõc: {info['file_size_mb']} MB")
            
            # Test ƒë·ªçc d·ªØ li·ªáu
            df = read_excel_file(test_file['file_path'])
            print(f"\nD·ªØ li·ªáu:")
            print(f"  - S·ªë d√≤ng: {len(df)}")
            print(f"  - S·ªë c·ªôt: {len(df.columns)}")
            print(f"  - C√°c c·ªôt: {list(df.columns)}")
            
            if not df.empty:
                print(f"\nD·ªØ li·ªáu m·∫´u (3 d√≤ng ƒë·∫ßu):")
                print(df.head(3).to_string(index=False))
            
            print(f"\nT·∫•t c·∫£ functions ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng!")
            
        except Exception as e:
            print(f"L·ªói khi test: {str(e)}")
    
    else:
        print("Th∆∞ m·ª•c uploads tr·ªëng.")
        print("\nH∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:")
        print("1. Ch·∫°y ·ª©ng d·ª•ng web: python app.py")
        print("2. Truy c·∫≠p: http://localhost:5000/excel-upload")
        print("3. Upload file Excel c·ªßa b·∫°n")
        print("4. Download v√† t·ª± ƒë·ªông x√≥a file")
    
    print("\n" + "=" * 60)

def get_images_from_drive_folder(drive_handler, folder_name, max_images=None):
    """
    L·∫•y ·∫£nh ƒë·∫ßu ti√™n t·ª´ Google Drive folder
    
    Args:
        drive_handler: GoogleDriveUploader instance
        folder_name: T√™n folder c·∫ßn t√¨m
        max_images: Kh√¥ng s·ª≠ d·ª•ng (ch·ªâ l·∫•y 1 ·∫£nh ƒë·∫ßu ti√™n)
    
    Returns:
        dict: Th√¥ng tin ·∫£nh ƒë·∫ßu ti√™n ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
    """
    try:
        # T√¨m folder theo t√™n
        folder_id = drive_handler.find_folder(folder_name)
        
        if not folder_id:
            print(f"Folder '{folder_name}' not found on Google Drive")
            return []
        
        print(f"Found folder '{folder_name}' with ID: {folder_id}")
        
        # List files trong folder
        query = f"'{folder_id}' in parents and mimeType contains 'image/'"
        
        results = drive_handler.service.files().list(
            q=query,
            orderBy='name',
            fields="files(id, name, webViewLink, webContentLink)"
        ).execute()
        
        files = results.get('files', [])
        
        if not files:
            print(f"No images found in folder '{folder_name}'")
            return None
        
        # Ch·ªâ l·∫•y ·∫£nh ƒë·∫ßu ti√™n
        first_file = files[0]
        print(f"Found {len(files)} images in folder '{folder_name}', using first image: {first_file['name']}")
        
        # Return th√¥ng tin ·∫£nh ƒë·∫ßu ti√™n (s·ª≠ d·ª•ng view link)
        file_id = first_file['id']
        view_url = f"https://drive.google.com/file/d/{file_id}/view"
        
        return {
            'name': first_file['name'],
            'url': view_url,
            'id': file_id
        }
        
    except Exception as e:
        print(f"Error getting images from folder '{folder_name}': {str(e)}")
        return None

def fill_excel_with_data(filename, products, column='E', start_row=7, fill_mode='repeat', sku_column='A', batch_column='CU', image_column='T', fill_images_from_drive=False):
    """
    Fill d·ªØ li·ªáu t·ª´ database v√†o file Excel
    
    Args:
        filename (str): T√™n file Excel c·∫ßn fill
        products (list): Danh s√°ch s·∫£n ph·∫©m t·ª´ database
        column (str): C·ªôt c·∫ßn fill (m·∫∑c ƒë·ªãnh 'E')
        start_row (int): D√≤ng b·∫Øt ƒë·∫ßu fill (m·∫∑c ƒë·ªãnh 7)
    
    Returns:
        dict: K·∫øt qu·∫£ fill d·ªØ li·ªáu
    """
    try:
        import openpyxl
        from datetime import datetime
        
        ensure_upload_folder()
        file_path = os.path.join(UPLOAD_FOLDER, filename)
        
        if not os.path.exists(file_path):
            return {
                'success': False,
                'error': f'File kh√¥ng t·ªìn t·∫°i: {filename}'
            }
        
        # ƒê·ªçc file Excel
        print(f"ƒêang ƒë·ªçc file: {file_path}")
        workbook = openpyxl.load_workbook(file_path)
        worksheet = workbook.active
        
        print(f"Sheet name: {worksheet.title}")
        print(f"Sheet dimensions: {worksheet.max_row} rows x {worksheet.max_column} columns")
        
        # Ki·ªÉm tra n·ªôi dung c·ªôt E tr∆∞·ªõc khi fill
        print(f"Checking existing data in column {column} from row {start_row-2} to {start_row+2}:")
        for check_row in range(max(1, start_row-2), start_row+3):
            cell_val = worksheet[f"{column}{check_row}"].value
            print(f"  {column}{check_row}: {cell_val}")
        
        # N·∫øu kh√¥ng c√≥ s·∫£n ph·∫©m th√¨ kh√¥ng l√†m g√¨
        if not products:
            print("Kh√¥ng c√≥ s·∫£n ph·∫©m ƒë·ªÉ fill!")
            return {
                'success': False,
                'error': 'Kh√¥ng c√≥ s·∫£n ph·∫©m trong collection'
            }
        
        # L·ªçc s·∫£n ph·∫©m c√≥ t√™n
        valid_products = [product for product in products if product.get('name', '').strip()]
        
        if not valid_products:
            print("Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o c√≥ t√™n!")
            return {
                'success': False,
                'error': 'Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o c√≥ t√™n trong collection'
            }
        
        print(f"Found {len(valid_products)} valid products to fill")
        print(f"Fill mode: {fill_mode}")
        print(f"Product name column: {column}, SKU column: {sku_column}, Batch ID column: {batch_column}")
        
        # Generate unique Batch ID cho to√†n b·ªô file n√†y
        from walmart import generate_batch_id
        batch_id = generate_batch_id()
        print(f"Generated Batch ID for this file: {batch_id}")
        
        # Initialize Google Drive handler if needed for images
        drive_handler = None
        if fill_images_from_drive:
            try:
                from google_drive_handler import GoogleDriveUploader
                drive_handler = GoogleDriveUploader()
                print(f"Google Drive connection established for image retrieval")
            except Exception as e:
                print(f"Warning: Could not connect to Google Drive for images: {str(e)}")
                fill_images_from_drive = False
        
        # T·ª± ƒë·ªông ph√°t hi·ªán d√≤ng cu·ªëi th·ª±c s·ª± c√≥ d·ªØ li·ªáu
        last_data_row = worksheet.max_row
        print(f"Excel max_row: {last_data_row}")
        
        # Scan t·ª´ cu·ªëi l√™n ƒë·ªÉ t√¨m d√≤ng cu·ªëi th·ª±c s·ª± c√≥ d·ªØ li·ªáu (kh√¥ng ph·∫£i d√≤ng tr·ªëng)
        actual_last_row = last_data_row
        for row_num in range(last_data_row, 0, -1):
            has_data = False
            for col_idx in range(1, worksheet.max_column + 1):
                cell_value = worksheet.cell(row=row_num, column=col_idx).value
                if cell_value is not None and str(cell_value).strip() != '':
                    has_data = True
                    break
            if has_data:
                actual_last_row = row_num
                break
        
        print(f"Actual last row with data: {actual_last_row}")
        
        # T√≠nh s·ªë d√≤ng c·∫ßn fill t·ª´ start_row ƒë·∫øn actual_last_row
        if actual_last_row < start_row:
            # N·∫øu file qu√° ng·∫Øn, fill √≠t nh·∫•t 10 d√≤ng
            fill_until_row = start_row + 9  # fill t·ª´ start_row ƒë·∫øn start_row+9 (10 d√≤ng)
            print(f"File ng·∫Øn, s·∫Ω fill 10 d√≤ng t·ª´ {start_row} ƒë·∫øn {fill_until_row}")
        else:
            fill_until_row = actual_last_row
            print(f"S·∫Ω fill t·ª´ d√≤ng {start_row} ƒë·∫øn d√≤ng {fill_until_row}")
        
        original_rows_to_fill = fill_until_row - start_row + 1
        print(f"Original rows to fill: {original_rows_to_fill}")
        
        # Prepare image mapping if needed
        product_images = {}
        if fill_images_from_drive and drive_handler:
            print(f"Preparing image mapping from Google Drive...")
            
            # Get unique product names for image mapping
            unique_product_names = set()
            for product in valid_products:
                name = product.get('name', '').strip()
                if name:
                    unique_product_names.add(name)
            
            print(f"Found {len(unique_product_names)} unique products for image mapping")
            
            # Get images for each unique product
            for product_name in unique_product_names:
                # Convert product name to folder name (same logic as Google Drive upload)
                import re
                clean_name = re.sub(r'[^\w\s-]', '', product_name)
                folder_name = re.sub(r'[-\s]+', '_', clean_name).strip('_')
                
                # Get first image from Google Drive folder
                first_image = get_images_from_drive_folder(drive_handler, folder_name)
                if first_image:
                    product_images[product_name] = first_image
                    print(f"üìÅ '{folder_name}': 1 image ‚Üí {first_image['name']}")
            
            print(f"Image mapping completed: {len(product_images)} products have images")
        
        filled_count = 0
        
        if fill_mode == 'duplicate':
            # DUPLICATE MODE: M·ªói s·∫£n ph·∫©m unique s·∫Ω c√≥ 1 nh√≥m d√≤ng ri√™ng
            unique_products = []
            seen_names = set()
            for product in valid_products:
                name = product.get('name', '').strip()
                if name and name not in seen_names:
                    unique_products.append(product)
                    seen_names.add(name)
            
            print(f"Found {len(unique_products)} unique products")
            
            current_row = start_row
            
            for group_index, unique_product in enumerate(unique_products):
                product_name = unique_product.get('name', '').strip()
                print(f"Processing group {group_index + 1}: '{product_name}' (rows {current_row}-{current_row + original_rows_to_fill - 1})")
                
                # Copy structure t·ª´ original rows n·∫øu kh√¥ng ph·∫£i group ƒë·∫ßu ti√™n
                if group_index > 0:
                    # Copy t·∫•t c·∫£ cells t·ª´ original group (start_row -> fill_until_row) 
                    # sang group hi·ªán t·∫°i (current_row -> current_row + original_rows_to_fill - 1)
                    for row_offset in range(original_rows_to_fill):
                        source_row = start_row + row_offset
                        target_row = current_row + row_offset
                        
                        # Copy t·∫•t c·∫£ cells trong d√≤ng (tr·ª´ c·ªôt product name, SKU, v√† batch ID)
                        for col_idx in range(1, worksheet.max_column + 1):
                            col_letter = worksheet.cell(row=1, column=col_idx).column_letter
                            if col_letter not in [column, sku_column, batch_column]:  # Kh√¥ng copy c√°c c·ªôt s·∫Ω fill m·ªõi
                                source_cell = worksheet.cell(row=source_row, column=col_idx)
                                target_cell = worksheet.cell(row=target_row, column=col_idx)
                                
                                # Copy value, style, format
                                target_cell.value = source_cell.value
                                if hasattr(source_cell, '_style'):
                                    target_cell._style = source_cell._style
                
                # Fill product name, SKU, v√† Batch ID v√†o t·∫•t c·∫£ d√≤ng c·ªßa group n√†y
                for row_offset in range(original_rows_to_fill):
                    target_row = current_row + row_offset
                    
                    # Fill product name
                    product_cell_address = f"{column}{target_row}"
                    worksheet[product_cell_address] = product_name
                    
                    # Generate v√† fill unique SKU  
                    from walmart import generate_unique_sku, mark_sku_used
                    unique_sku = generate_unique_sku()
                    sku_cell_address = f"{sku_column}{target_row}"
                    worksheet[sku_cell_address] = unique_sku
                    mark_sku_used(unique_sku)
                    
                    # Fill Batch ID (c√πng gi√° tr·ªã cho t·∫•t c·∫£ d√≤ng)
                    batch_cell_address = f"{batch_column}{target_row}"
                    worksheet[batch_cell_address] = batch_id
                    
                    # Fill image from Google Drive if available (same image for all rows)
                    if fill_images_from_drive and product_name in product_images:
                        image_data = product_images[product_name]
                        image_url = image_data['url']
                        image_cell_address = f"{image_column}{target_row}"
                        worksheet[image_cell_address] = image_url
                        
                        if filled_count <= 10 or filled_count % 50 == 0:
                            print(f"  Image: {image_cell_address} = {image_data['name']}")
                    
                    filled_count += 1
                    
                    if filled_count <= 10 or filled_count % 50 == 0:
                        print(f"Fill #{filled_count}: {product_cell_address} = '{product_name}', {sku_cell_address} = '{unique_sku}', {batch_cell_address} = '{batch_id}' (group {group_index + 1})")
                
                # Move to next group
                current_row += original_rows_to_fill
            
            total_filled_rows = len(unique_products) * original_rows_to_fill
            print(f"Duplicate mode completed: {len(unique_products)} groups √ó {original_rows_to_fill} rows = {total_filled_rows} total rows")
            
        else:
            # REPEAT MODE: L·∫∑p l·∫°i danh s√°ch s·∫£n ph·∫©m nh∆∞ c≈©
            current_row = start_row
            product_index = 0
            
            print(f"Starting repeat mode: fill {original_rows_to_fill} rows from row {start_row} to {fill_until_row}")
            
            while filled_count < original_rows_to_fill and current_row <= fill_until_row:
                # L·∫•y s·∫£n ph·∫©m theo v√≤ng l·∫∑p (cycle through products)
                product = valid_products[product_index % len(valid_products)]
                product_name = product.get('name', '').strip()
                
                if product_name:
                    # Fill product name
                    product_cell_address = f"{column}{current_row}"
                    worksheet[product_cell_address] = product_name
                    
                    # Generate v√† fill unique SKU
                    from walmart import generate_unique_sku, mark_sku_used
                    unique_sku = generate_unique_sku()
                    sku_cell_address = f"{sku_column}{current_row}"
                    worksheet[sku_cell_address] = unique_sku
                    mark_sku_used(unique_sku)
                    
                    # Fill Batch ID (c√πng gi√° tr·ªã cho t·∫•t c·∫£ d√≤ng)
                    batch_cell_address = f"{batch_column}{current_row}"
                    worksheet[batch_cell_address] = batch_id
                    
                    # Fill image from Google Drive if available (same image for all rows)
                    if fill_images_from_drive and product_name in product_images:
                        image_data = product_images[product_name]
                        image_url = image_data['url']
                        image_cell_address = f"{image_column}{current_row}"
                        worksheet[image_cell_address] = image_url
                        
                        if filled_count <= 5 or filled_count % 50 == 0:
                            print(f"  Image: {image_cell_address} = {image_data['name']}")
                    
                    filled_count += 1
                    
                    # Verify data was written
                    verify_product_value = worksheet[product_cell_address].value
                    verify_sku_value = worksheet[sku_cell_address].value
                    verify_batch_value = worksheet[batch_cell_address].value
                    
                    # Debug output for first few and every 50th item
                    if filled_count <= 5 or filled_count % 50 == 0:
                        print(f"Fill #{filled_count}: {product_cell_address} = '{product_name}' (verified: '{verify_product_value}'), {sku_cell_address} = '{unique_sku}' (verified: '{verify_sku_value}'), {batch_cell_address} = '{batch_id}' (verified: '{verify_batch_value}') [product #{product_index % len(valid_products) + 1}]")
                    
                    current_row += 1
                    product_index += 1
                else:
                    # Skip s·∫£n ph·∫©m kh√¥ng c√≥ t√™n
                    product_index += 1
                    continue
        
        # Ki·ªÉm tra l·∫°i sau khi fill
        print(f"After filling, checking column {column} from row {start_row} to {start_row+min(5, filled_count)}:")
        for check_row in range(start_row, start_row + min(5, filled_count) + 1):
            cell_val = worksheet[f"{column}{check_row}"].value
            print(f"  {column}{check_row}: {cell_val}")
        
        # T·∫°o t√™n file m·ªõi
        name_part, ext = os.path.splitext(filename)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        new_filename = f"{name_part}_filled_{timestamp}{ext}"
        new_file_path = os.path.join(UPLOAD_FOLDER, new_filename)
        
        print(f"Saving to: {new_file_path}")
        
        # L∆∞u file m·ªõi
        workbook.save(new_file_path)
        workbook.close()
        
        # Verify file was saved and check size
        if os.path.exists(new_file_path):
            file_size = os.path.getsize(new_file_path)
            print(f"File saved successfully: {new_file_path} ({file_size} bytes)")
            
            # Quick verification by reopening file
            verify_workbook = openpyxl.load_workbook(new_file_path)
            verify_worksheet = verify_workbook.active
            sample_cell = verify_worksheet[f"{column}{start_row}"]
            print(f"Verification - {column}{start_row} in saved file: '{sample_cell.value}'")
            verify_workbook.close()
        else:
            print(f"ERROR: File was not saved!")
        
        print(f"ƒê√£ l∆∞u file m·ªõi: {new_file_path}")
        print(f"ƒê√£ fill {filled_count} s·∫£n ph·∫©m")
        
        # Mark Batch ID as used
        from walmart import mark_batch_used
        mark_batch_used(batch_id, filled_count)
        
        if fill_mode == 'duplicate':
            unique_count = len(set(p.get('name', '').strip() for p in valid_products if p.get('name', '').strip()))
            base_message = f'Ch·∫ø ƒë·ªô duplicate: {unique_count} s·∫£n ph·∫©m unique √ó {original_rows_to_fill} d√≤ng = {filled_count} t·ªïng d√≤ng ƒë√£ fill (Product Name + SKU + Batch ID: {batch_id}'
            if fill_images_from_drive:
                image_count = len(product_images)
                base_message += f' + Images t·ª´ {image_count} Google Drive folders'
            message = base_message + ')'
            end_row = start_row + filled_count - 1
        else:
            base_message = f'Ch·∫ø ƒë·ªô repeat: ƒê√£ fill {filled_count} d√≤ng v√†o c·ªôt {column} (Product Name), {sku_column} (SKU) v√† {batch_column} (Batch ID: {batch_id})'
            if fill_images_from_drive:
                image_count = len(product_images)
                base_message += f', {image_column} (Images t·ª´ {image_count} Google Drive folders)'
            message = base_message + f' t·ª´ d√≤ng {start_row} ƒë·∫øn {fill_until_row}'
            end_row = fill_until_row
        
        return {
            'success': True,
            'filled_count': filled_count,
            'new_filename': new_filename,
            'column': column,
            'sku_column': sku_column,
            'batch_column': batch_column,
            'batch_id': batch_id,
            'image_column': image_column if fill_images_from_drive else None,
            'images_filled': len(product_images) if fill_images_from_drive else 0,
            'start_row': start_row,
            'end_row': end_row,
            'fill_mode': fill_mode,
            'total_rows_detected': original_rows_to_fill,
            'message': message
        }
        
    except Exception as e:
        print(f"Error in fill_excel_with_data: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'error': f'L·ªói khi fill d·ªØ li·ªáu: {str(e)}'
        }
